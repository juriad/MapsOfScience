This is a post by Ivory2Match on Reddit. I comment it to make it easier to understand.
https://www.reddit.com/r/java/comments/13rlb26/speeding_up_pairwise_comparisons_to_28_millionsec/jlm0me1/

Let's serialize the whole thing into one large int[] array. Its structure will be:

    journal index
    number of authors
    sorted author indices

So a small sample of 4 journals with (3, 3, 5, 2) authors:

< 0 : 3 . 0 5 50 >
< 1 : 3 . 2 3 5 >
< 2 : 5 . 3 6 49 50 97 >
< 3 : 2 . 30 230 >

Then the method computeSimilarities will take two indices instead of sets. We use the fact that the lists of authors are sorted, so we will iterate over both at once.

// indices of the last authors
int flast = first + 1 + array[first + 1];
int slast = first + 1 + array[second + 1];

// indices of the first authors
// (potentially beyond last, when 0 authors) <-- not sure what this means?

int f = first + 2;
int s = second + 2;

int matches = 0;

// authors
int fa = -1;
int sa = -1;

while (f <= flast && s <= slast) {
  if (fa < 0) {
    fa = array[f];
  }
  if (sa < 0) {
    sa = array[s];
  }

  if (fa < sa) {
    f++; fa = -1;
  }
  else if (fa > sa) {
    s++; sa = -1;
  }
  else { 
    matches++; 
    f++; fa = -1;
    s++; sa = -1;
  } 
}

System.out.println("Journals with indices " + array[first] + " and " + array[second] + " have " + matches + " authors in common");

return matches;

This algorithm touches each element of the array belonging to the journal exactly once. Moreover, the pattern of the accesses is linear which is what CPUs like (memory prefetch).

Second step is iteration over the journals. Let's call it loopOverSeconds which has a single parameter first.

int second = first + 2 + array[first + 1];
while (second < array.length) {
  computeSimilarities(first, second);
  second += array[second + 1] + 2;
}

We start with the journal which is immediately after first and then just jump by number of authors plus 2.

We can use the method for iterating over first but we want to start using parallelism. Virtual threads will not help us because there is nowhere to suspend them, so it is better to create fixed number of threads (equal to number of cores; and play with hyper threading).

These threads will take work from an array of firsts (indices where all journals start in the array. We will synchronize the access through an AtomicInteger next which marks the index in firsts that should be processed next.

Each thread then gets and increments next, finds first and performs matches over all seconds (see above).

int n;
while((n = next.getAndIncrement()) < firsts.length) {
  int first = firsts[n];
  loopOverSeconds(first);
}

Each thread performs relatively large piece of work which means that less time is spent on the synchronization and Thread scheduling. There is absolutely no boxing anywhere. The array firsts is also accessed in a linear fashion.

Notice that the code would be almost the same in C or any other low-level language which tells us that we don't have any overhead imposed by OOP and are therefore very close to optimum."